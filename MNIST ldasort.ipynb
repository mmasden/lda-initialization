{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Custom Tools\n",
    "import ldasort.ldasort as ldasort\n",
    "\n",
    "## Import Standard Data Processing Tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import ML tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD FASHION MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "data_set = \"MNIST\"\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#normalize\n",
    "x_train_normalized = (x_train - np.mean(x_train))/np.std(x_train) \n",
    "x_test_normalized = (x_test - np.mean(x_train))/np.std(x_train)\n",
    "\n",
    "#flatten and reshape\n",
    "x_train_normalized = x_train_normalized.reshape(60000,28*28)\n",
    "x_test_normalized = x_test_normalized.reshape(10000,28*28)\n",
    "y_train=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weights and biases using LDA sorting algorithm. \n",
    "# Comment out if weights already present. \n",
    "\n",
    "weights, biases = ldasort.ldasort(x_train_normalized, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights and biases for use later\n",
    "np.savez(\"Sorted_Weights_{}\".format(dataset), weights=weights, biases=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create loop for comparing across batch sizes, learning rates\n",
    "\n",
    "learning_rates = [.001, .005, .01]\n",
    "batch_sizes = [25, 100, 500]\n",
    "\n",
    "#small values for quick sample run \n",
    "n_trials = 5\n",
    "n_epochs = 5\n",
    "\n",
    "t0=timer()\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "\n",
    "        temp_hists=[]\n",
    "        val_hists=[]\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "\n",
    "            #set up LDA-initialized model\n",
    "            \n",
    "            model=setup(factors=len(all_weights),input_shape=784, output_shape=10)\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=keras.optimizers.SGD(lr=lr),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'],\n",
    "                    weighted_metrics=['accuracy']\n",
    "                    )\n",
    "\n",
    "            model.layers[0].set_weights([all_weights.T,all_biases])\n",
    "            \n",
    "            t0loss, t0acc, t0wacc = model.evaluate(X,y_train,verbose=False)\n",
    "\n",
    "\n",
    "            history=model.fit(X, \n",
    "                      y_train, \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=batch_size,\n",
    "                      validation_data = (x_test_normalized, y_test),\n",
    "                      verbose=False)\n",
    "\n",
    "            temp_hists.append([t0acc]+history.history['acc'])\n",
    "            print(\"LDA trial {} Done, time elapsed {} minutes\".format(trial, np.round((timer()-t0)/60),3))\n",
    "\n",
    "            keras.backend.clear_session()\n",
    "\n",
    "        lda_hist = temp_hists\n",
    "        val_lda_hist=val_hists\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        #Run Trials with Random Initialization#\n",
    "        #######################################\n",
    "        temp_hists=[]\n",
    "        val_hists=[]\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "\n",
    "\n",
    "            model=setup(factors=len(all_weights),input_shape=784, output_shape=10)\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=keras.optimizers.SGD(lr=lr),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'],\n",
    "                    weighted_metrics=['accuracy']\n",
    "                    )\n",
    "            \n",
    "            t0loss, t0acc, t0wacc = model.evaluate(X,y_train,verbose=False)\n",
    "\n",
    "\n",
    "            history=model.fit(X, \n",
    "                      y_train, \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=batch_size,\n",
    "                      validation_data = (x_test_normalized, y_test),\n",
    "                      verbose=False)\n",
    "\n",
    "            temp_hists.append([t0acc]+history.history['acc'])\n",
    "            print(\"Random trial {} Done, time elapsed {} minutes\".format(trial, np.round((timer()-t0)/60)),3)\n",
    "\n",
    "            keras.backend.clear_session()\n",
    "\n",
    "        rand_hist = temp_hists\n",
    "        val_rand_hist=val_hists\n",
    "\n",
    "\n",
    "        np.savez(\"{}_sigmoid_lr{}_bat{}\".format(data_set, lr,batch_size), \n",
    "                 lda_acc=lda_hist, \n",
    "                 val_lda_acc=val_lda_hist,\n",
    "                 rand_acc = rand_hist, \n",
    "                 val_rand_acc = val_rand_hist,\n",
    "                 n_components=len(all_weights), \n",
    "                num_trials=n_trials,\n",
    "                n_epochs = n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
